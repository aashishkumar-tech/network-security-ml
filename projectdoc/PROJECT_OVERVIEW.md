# Network Security - Phishing Detection Project

## ğŸ¯ Project Overview

This is an end-to-end machine learning project for **phishing website detection** using network security data. The project implements a complete MLOps pipeline with experiment tracking, data versioning, and deployment capabilities.

## ğŸ—ï¸ Architecture

```
Data Source (MongoDB) â†’ Data Ingestion â†’ Data Validation â†’ 
Data Transformation â†’ Model Training â†’ Model Evaluation â†’ 
Model Deployment (FastAPI + Docker) â†’ Predictions
```

## ğŸ”‘ Key Features

### 1. **MongoDB Integration**

- Cloud-based data storage using MongoDB Atlas
- Dynamic data fetching from database
- Scalable data management
- Collection: `NetworkData`
- Database: `AashishKumarTechDB`

### 2. **MLflow Experiment Tracking**

- Automatic logging of model metrics
- Parameter tracking
- Model versioning
- Experiment comparison

### 3. **DagHub Integration**

- Centralized experiment tracking
- Model registry
- Collaboration features
- Git + Data + Models in one place

### 4. **Docker Deployment**

- Containerized application for consistent deployment
- Docker Compose support for easy orchestration
- Automated deployment scripts (Windows & Linux)
- Production-ready container configuration
- Health checks and restart policies
- Volume mounting for persistent data

### 5. **Modular Pipeline Architecture**

- **Data Ingestion**: MongoDB â†’ CSV
- **Data Validation**: Schema validation + Drift detection
- **Data Transformation**: KNN Imputation + Feature engineering
- **Model Training**: Multiple algorithms with GridSearchCV
- **Model Evaluation**: Classification metrics

### 6. **Production-Ready API**

- FastAPI for REST API
- CSV file upload for batch predictions
- Real-time inference
- HTML response with prediction table

## ğŸ“Š Models Trained

- Random Forest Classifier
- Decision Tree Classifier
- Gradient Boosting Classifier
- Logistic Regression
- AdaBoost Classifier

**Best model selected automatically** based on test RÂ² score.

## ğŸ”„ Data Flow

1. **Push Data**: `push_data.py` â†’ MongoDB
2. **Training**: `main.py` â†’ Artifacts + Models
3. **Prediction**: `app.py` â†’ API endpoints

## ğŸ“ Project Structure

```
networksecurity/
â”œâ”€â”€ networksecurity/           # Main package
â”‚   â”œâ”€â”€ components/            # Pipeline components
â”‚   â”œâ”€â”€ pipeline/              # Training & batch prediction
â”‚   â”œâ”€â”€ constant/              # Configuration constants
â”‚   â”œâ”€â”€ entity/                # Data classes (config, artifacts)
â”‚   â”œâ”€â”€ exception/             # Custom exception handling
â”‚   â”œâ”€â”€ logging/               # Logging configuration
â”‚   â”œâ”€â”€ utils/                 # Utility functions
â”‚   â””â”€â”€ cloud/                 # AWS S3 sync (optional)
â”œâ”€â”€ Artifacts/                 # Training artifacts (generated)
â”œâ”€â”€ final_model/               # Production models
â”œâ”€â”€ Network_Data/              # Raw data
â”œâ”€â”€ projectdoc/                # Documentation
â”œâ”€â”€ .env                       # Environment variables
â”œâ”€â”€ main.py                    # Training pipeline entry
â”œâ”€â”€ app.py                     # FastAPI application
â”œâ”€â”€ push_data.py               # Data upload script
â””â”€â”€ requirements.txt           # Dependencies
```

## ğŸš€ Technology Stack

- **Python 3.8+**
- **Machine Learning**: scikit-learn
- **Experiment Tracking**: MLflow + DagHub
- **Database**: MongoDB Atlas
- **API Framework**: FastAPI
- **Data Processing**: Pandas, NumPy
- **Validation**: Scipy (KS test for drift detection)

## ğŸ“ˆ Performance Metrics

The model is evaluated using:

- **F1 Score**: Harmonic mean of precision and recall
- **Precision**: Correct positive predictions
- **Recall**: Coverage of actual positives

All metrics logged to DagHub for tracking and comparison.

## ğŸ” Security Features

- Environment variables for credentials
- MongoDB authentication
- Secure API endpoints
- Exception handling throughout

## ğŸŒ Deployment Ready

- **Dockerized Application**:
  - Optimized Dockerfile with multi-stage builds
  - Docker Compose for orchestration
  - Automated deployment scripts (.ps1 for Windows, .sh for Linux)
  - Health checks and auto-restart policies
- **AWS S3 Integration**: Artifact storage and model versioning
- **FastAPI**: Scalable API serving with interactive docs
- **Model Versioning**: Timestamped artifacts for traceability

## ğŸ“ Use Cases

- **Real-time phishing detection**
- **Batch URL analysis**
- **Security monitoring systems**
- **Cybersecurity research**

## ğŸ“ Learning Outcomes

This project demonstrates:

- End-to-end ML pipeline development
- MLOps best practices
- Cloud database integration
- Experiment tracking
- API development
- Production-ready code structure
